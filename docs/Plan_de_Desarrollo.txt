# Plan de Desarrollo - Proyecto Lucy
## Asistente de IA de Escritorio Inteligente

Este documento define el objetivo, la arquitectura, las estrategias y las acciones para desarrollar Lucy con un flujo lógico y trazable: de los objetivos a acciones, entregables, pruebas y métricas. Todas las referencias de módulos usan la estructura `src/lucy/*`.

### Objetivo General
- Construir un asistente de IA local, extensible y confiable, con respuestas rápidas, capacidad de aprendizaje y observabilidad completa.

### Arquitectura y Componentes
- `src/lucy/lucy_ai.py`: motor de conversación, detección de intención y generación de respuesta.
- `src/lucy/database.py`: `ConversationDB` para sesiones, contexto y historial.
- `src/lucy/config_manager.py`: `ConfigManager` y `ConfigWatcher` para configuración dinámica.
- `src/lucy/logging_system.py`: logging estructurado, métricas y trazabilidad.
- `src/lucy/training.py`: pipeline de entrenamiento y evaluación de modelos.
- `src/lucy/utils.py`: utilidades (normalización de texto, saludos, etc.).

### Diagrama de Arquitectura (alto nivel)
```
[Usuario]
   │
   ▼
[LucyAI] ──► [ConfigManager]
   │             │
   │             └── Carga y aplica configuración (runtime)
   │
   ├─► [Intent Detection / Respuesta]
   │        │
   │        └── Usa modelos y reglas
   │
   ├─► [ConversationDB]
   │        └── Guarda/recupera contexto e historial
   │
   └─► [LoggingSystem]
            └── Logs, métricas y auditoría

[Training] ───► [Modelos en disco] ───► [LucyAI]
```

### Flujo End-to-End (conexión entre componentes)
1. Entrada del usuario → normalización → detección de idioma → intención.
2. Generación de respuesta → actualización de contexto → persistencia en `ConversationDB`.
3. Logging y métricas (latencia, confianza, idioma, intención, errores).
4. Configuración dinámica puede ajustar comportamiento (p. ej., límites de historial, idioma preferido).
5. Entrenamiento produce/actualiza modelos → Lucy los carga bajo demanda.

### Estrategia de Implementación
- Iterar por fases, asegurando en cada día: objetivo claro, acciones atómicas, entregables verificables, criterios de aceptación, métricas y dependencias explícitas.
- Conectar tareas con pruebas (`tests/`) y documentación (`docs/`), con puertas de calidad (coverage y lint).

---

### Fase 1: Optimización y Base Sólida (Días 1-7)

**Día 1: Reestructuración y Limpieza del Código**
- Objetivo: consolidar la estructura en `src/lucy` y sanear imports/errores.
- Estrategia: mover módulos, normalizar rutas y manejo de errores.
- Acciones:
  - Reorganizar carpetas a `src/lucy/*` y actualizar imports.
  - Normalizar separadores en `ConfigManager.get_path` y paths relativos.
  - Manejo de `FileNotFoundError` en `LucyAI` para modelos y datos.
- Entregables: código consistente y ejecutable; documentación de estructura.
- Criterios de aceptación: ejecución local sin errores; tests básicos pasan.
- Métricas: tiempo de arranque; conteo de errores en logs.
- Dependencias: ninguna.

**Día 2: Sistema de Logging y Monitoreo**
- Objetivo: observabilidad con logs estructurados y métricas.
- Estrategia: configurar `logging.yaml`, niveles, formatos y sumarios.
- Acciones:
  - Implementar `LoggingSystem` y hooks en `LucyAI` y `Database`.
  - Métricas: latencia, confidencia, intención, volumen por idioma.
  - Exportar `lucy.logging_system` para import claro.
- Entregables: panel básico de métricas en archivo y/o consola.
- Criterios de aceptación: logs presentes por ruta crítica; métricas visibles.
- Métricas: latencia promedio < 2s; errores críticos = 0.
- Dependencias: Día 1.

**Día 3: Mejora del Sistema de Entrenamiento**
- Objetivo: reproducibilidad y calidad de modelos.
- Estrategia: EarlyStopping, ReduceLROnPlateau, CSVLogger; validación de datos.
- Acciones:
  - `training.py`: pipeline con semillas y guardado de mejor modelo.
  - Validación de `data/intents/*.json` y split train/val.
  - Métricas de evaluación (accuracy, F1) y reporte.
- Entregables: modelo entrenado y artefactos de evaluación.
- Criterios de aceptación: métricas mínimas; carga del modelo desde `LucyAI`.
- Métricas: F1 > 0.80 en intents base.
- Dependencias: Día 2.

**Día 4: Base de Datos de Conversaciones**
- Objetivo: persistencia y contexto estable.
- Estrategia: `ConversationDB` con sesiones, límites de historial y expiración de contexto.
- Acciones:
  - Implementar `save_conversation(...)` y recuperación de historial.
  - API de contexto: `set_context`, `get_session_context`.
  - Índices y consultas de búsqueda básicas.
- Entregables: historial consultable por sesión; contexto operativo.
- Criterios de aceptación: pruebas en `tests/test_lucy_ai.py` pasan.
- Métricas: tiempo de escritura/lectura; tamaño medio de sesión.
- Dependencias: Día 1.

**Día 5: Sistema de Configuración Dinámico**
- Objetivo: ajustar comportamiento en tiempo real.
- Estrategia: `ConfigWatcher` sobre `config/config.json` con observadores.
- Acciones:
  - Hot-reload de parámetros (p. ej., idioma, límites, respuestas).
  - Observers conectados en `LucyAI`, `LoggingSystem`, `Database`.
- Entregables: cambio de config sin reinicio.
- Criterios de aceptación: modificación de JSON refleja cambios inmediatos.
- Métricas: latencia de propagación de cambios < 500 ms.
- Dependencias: Días 1-2.

**Día 6: Testing y Calidad de Código**
- Objetivo: asegurar estabilidad con pruebas y cobertura, con arquitectura de pruebas escalable y mantenible.
- Alcance: pruebas unitarias e integración para `LucyAI`, `ConversationDB`, `ConfigManager`, `LoggingSystem` y `Training`; cobertura y pipeline local de CI.

1) Dependencias técnicas y requisitos por funcionalidad
- `LucyAI` (src/lucy/lucy_ai.py): depende de `ConfigManager`, `ConversationDB`, `LoggingSystem`, datos `data/intents/*` y modelos en disco. Requisitos: fixtures para datos/modelos, semillas determinísticas, mock de `LoggingSystem` y/o captura con `caplog`.
- `ConversationDB` (src/lucy/database.py): usa `sqlite3`; requiere DB temporal vía `tmp_path`, uso de timestamps en formato string (`YYYY-MM-DD HH:MM:SS`), atomicidad de transacciones y pruebas de concurrencia ligera.
- `ConfigManager` (src/lucy/config_manager.py): lee `config/config.json` y watchers; requiere archivo de config de prueba aislado, simulación de cambios en disco y verificación de propagación sin condiciones de carrera.
- `LoggingSystem` (src/lucy/logging_system.py): formatea JSON con `pythonjsonlogger.json.JsonFormatter`; requiere validación de estructura de log, niveles y ausencia de datos sensibles.
- `Training` (src/lucy/training.py): depende de `data/intents/*.json`; requiere dataset sintético de prueba, semilla fija, tiempo de ejecución acotado y verificación de guardado/carga de modelo.

2) Arquitectura óptima de pruebas
- Framework: `pytest` + `pytest-cov` (cobertura). Comando: `pytest -q --cov=src/lucy --cov-report=term-missing`.
- Estructura de módulos de prueba en `tests/`:
  - `test_lucy_ai.py`, `test_database.py`, `test_config_manager.py`, `test_logging.py`, `test_training.py`.
- Fixtures reutilizables en `tests/conftest.py`:
  - `temp_db_path(tmp_path)` y `conversation_db(temp_db_path)` para DB aislada.
  - `test_config(tmp_path)` y `config_manager(test_config)` para override de configuración.
  - `dummy_model_path(tmp_path)` y `lucy_ai(config_manager, conversation_db, dummy_model_path)` para orquestar el motor con dependencias.
  - `disable_json_logging(monkeypatch)` para forzar formatter simple cuando convenga.
- Datos de prueba: `src/test_data` y mocks generados en tiempo de test.

3) Módulos y componentes necesarios
- Pruebas por componente:
  - LucyAI: intents, lenguaje, respuestas y latencia.
  - ConversationDB: persistencia, historial, métricas y limpieza.
  - ConfigManager: carga, reload y propagación de cambios.
  - LoggingSystem: formato JSON, niveles y trazabilidad.
  - Training: pipeline completo, guardado y carga del modelo.
- Utilidades de test: helpers para construir intents válidos y sesiones.

4) Flujos de datos y procesos clave (tests e2e)
- LucyAI: input → normalización → intención → respuesta → `save_conversation` → log → recuperar historial → aserciones.
- DB: inserción/consulta → `cleanup_old_data` → `get_metrics_summary` → aserciones de tipos y conteos.
- Config: escribir nuevo JSON → watcher detecta → componentes ajustan comportamiento → validar latencia de propagación.
- Logging: emitir registros → capturar con `caplog` → parsear JSON → aserciones de campos.
- Training: cargar dataset → entrenar → guardar modelo → cargar en `LucyAI` → validar predicciones.

5) Criterios de validación y pruebas unitarias
- LucyAI: respuesta no vacía, intención válida, idioma detectado, fallback ante intent desconocido, p95 latencia local < 2s.
- ConversationDB: `save_conversation` persiste; `get_session_history` retorna último N; `get_metrics_summary` entrega dicts con campos esperados; `cleanup_old_data` elimina registros antiguos.
- ConfigManager: carga por defecto; reload en cambio de archivo; manejo de JSON inválido con log de error; observadores notificados.
- LoggingSystem: registros en JSON con campos `timestamp`, `session_id`, `intent`, `confidence`; niveles correctos; sin datos sensibles; sin deprecations de import.
- Training: métricas mínimas calculadas (accuracy/F1 sobre dataset sintético); guardado de mejor modelo; carga desde disco; errores manejados ante dataset vacío o inválido.

6) Acciones detalladas
- Ampliar `tests/` con casos por componente y parametrizaciones.
- Añadir `tests/conftest.py` con fixtures descritas y datos sintéticos.
- Configurar cobertura y reporte; umbral mínimo 85% (camino a 90%).
- Gating local: script o tarea que ejecute `pytest -q --cov=src/lucy --disable-warnings`.

7) Casos límite y manejo de errores
- Config ausente o inválido: fallback a valores por defecto y log de error.
- DB bloqueada o ruta no escribible: reintentos limitados, mensaje de error y abortar operación con estado claro.
- JSON de intents corrupto: validación previa, excepción controlada y reporte.
- Entrenamiento sin datos: terminar temprano con mensaje y no generar modelo.
- Watchers de config: evitar condiciones de carrera con bloqueos ligeros.

8) Documentación técnica
- Actualizar `docs/` con guía de ejecución de pruebas y cobertura.
- Comandos recomendados:
  - `pytest -q`
  - `pytest -q --cov=src/lucy --cov-report=term-missing`
  - `pytest -q -k "lucy_ai or database"`
- Incluir matriz de casos y trazabilidad a objetivos de calidad.

9) Ejemplos de código (referencia)
```python
# tests/conftest.py
import json
import os
import pytest
from src.lucy.database import ConversationDB
from src.lucy.config_manager import ConfigManager
from src.lucy.lucy_ai import LucyAI

@pytest.fixture
def temp_db_path(tmp_path):
    return tmp_path / "test.db"

@pytest.fixture
def conversation_db(temp_db_path):
    db = ConversationDB(str(temp_db_path))
    yield db

@pytest.fixture
def test_config(tmp_path):
    cfg = {"language": "es", "history_limit": 10}
    p = tmp_path / "config.json"
    p.write_text(json.dumps(cfg), encoding="utf-8")
    return str(p)

@pytest.fixture
def config_manager(test_config):
    return ConfigManager(config_path=test_config)

@pytest.fixture
def lucy_ai(config_manager, conversation_db):
    return LucyAI(config=config_manager, db=conversation_db)
```

```python
# tests/test_logging.py
import json
import logging
from src.lucy.logging_system import LoggingSystem

def test_json_logging_structure(caplog):
    ls = LoggingSystem({"json_logging": True})
    logger = ls.get_logger("test")
    with caplog.at_level(logging.INFO):
        logger.info("hola", extra={"session_id": "s1", "intent": "saludo", "confidence": 0.9})
    record = caplog.records[-1]
    payload = json.loads(record.message)
    assert set(["timestamp","session_id","intent","confidence"]).issubset(payload.keys())
```

- Entregables: suite de pruebas, cobertura ≥ 85%, pipeline local de CI y documentación actualizada.
- Criterios de aceptación: `pytest -q` sin fallos; cobertura >= 85%; sin `DeprecationWarning` en rutas críticas.
- Métricas: cobertura por módulo, tasa de fallos por commit y latencia media en `LucyAI`.
- Dependencias: Días 1-5.

**Día 7: Documentación y Deployment**
- Objetivo: facilitar instalación, uso y mantenimiento.
- Estrategia: README, guías en `docs/`, scripts de arranque.
- Acciones:
  - Actualizar docs con `src/lucy/*` y ejemplos reales.
  - Scripts `run_lucy.*` y guía de troubleshooting.
- Entregables: documentación completa y scripts funcionales.
- Criterios de aceptación: instalación y ejecución guiadas sin bloqueos.
- Métricas: tiempo de onboarding < 30 min.
- Dependencias: Días 1-6.

---

### Fase 2: Funcionalidades Core (Días 8-14)

Para cada día se aplicará el mismo esquema (Objetivo, Estrategia, Acciones, Entregables, Criterios, Métricas, Dependencias). A continuación, se detallan los puntos críticos de implementación.

**Día 8: Sistema de Plugins**
- Objetivo: extensibilidad modular sin comprometer estabilidad ni seguridad.
- Integración: `LucyAI` orquesta `PluginManager` con hooks (`on_start`, `on_message`, `on_stop`); trazabilidad en `LoggingSystem` por plugin.
- Estrategia: cargador dinámico con registro y contratos claros (`Plugin`), aislamiento de excepciones y modo seguro.
- Acciones:
  - Crear `src/lucy/plugins/base.py` (interfaz y contrato), `src/lucy/plugins/manager.py` (descubrimiento, carga/descarga).
  - Añadir `src/lucy/plugins/examples/*.py` para validación y guía.
  - Integrar en `LucyAI` la fase de hooks y propagación de eventos.
- Configuración: `config/config.json` → `plugins.enabled`, `plugins.paths`, `plugins.safe_mode`.
- Requisitos: Python 3.10+; compatibilidad Windows/macOS/Linux; logs JSON por plugin.
- Criterios de aceptación: carga/descarga segura; fallos de un plugin no afectan el core; logs completos.
- Pruebas: unitarias del manager (descubrimiento, contratos, errores) e integración con `LucyAI`.
- Dependencias: Config estable (Día 5) y Logging (Día 2).

**Día 9: Integración con APIs Externas**
- Objetivo: consumir servicios externos de forma segura y resiliente.
- Integración: `LucyAI` invoca clientes de `src/lucy/services` mediante interfaces; métricas en `LoggingSystem`.
- Estrategia: clientes HTTP con autenticación, timeouts, reintentos exponenciales y cache local.
- Acciones:
  - Crear `src/lucy/services/client_base.py` y clientes específicos (`client_{service}.py`).
  - Añadir manejo de credenciales (env/archivo seguro) y rate limiting por servicio.
  - Mocks y sandbox para pruebas (respuestas controladas).
- Configuración: `apis.{service}.base_url`, `auth`, `timeout`, `retry.max_attempts`, `cache.ttl`.
- Requisitos: `httpx>=0.27`, `tenacity>=8.2`, `pydantic>=2.6`.
- Criterios de aceptación: timeouts y reintentos efectivos; errores manejados; métricas de éxito/fracaso.
- Pruebas: integración con mock/sandbox, latencia y correctitud de parseo.

**Día 10: PLN Avanzado**
- Objetivo: mejorar intención, entidades y sentimientos con pipeline opcional.
- Integración: `LucyAI` consulta `src/lucy/nlp/pipeline.py` si `nlp.enabled=true`; fallback a reglas base si falla.
- Estrategia: pipeline con `spaCy/Transformers`; normalización, tokenización y scoring configurable.
- Acciones:
  - Crear `src/lucy/nlp/{__init__.py,pipeline.py}` con interfaces y modelos configurables.
  - Añadir modelos de prueba en `src/test_models/` y utilidades de normalización.
- Configuración: `nlp.enabled`, `nlp.model`, `nlp.thresholds` (intención/entidades/sentimiento).
- Requisitos: `spacy>=3.7`, `transformers>=4.44`, `sentence-transformers>=2.2` (opcionales).
- Criterios de aceptación: mejora de métricas vs baseline y fallback transparente.
- Pruebas: unitarias de pipeline, rendimiento básico y compatibilidad con `LucyAI`.

**Día 11: Memoria a Largo Plazo**
- Objetivo: enriquecer contexto con recuperación semántica de información pasada.
- Integración: `src/lucy/memory/store.py` conectado a `ConversationDB`; API `search_semantic(query)` usada por `LucyAI`.
- Estrategia: embeddings + vector store local; índices y mantenimiento.
- Acciones: crear `src/lucy/memory/{store.py,embeddings.py}` y jobs de indexado.
- Configuración: `memory.enabled`, `memory.backend`, `memory.dimensions`, `memory.ttl`.
- Requisitos: `sentence-transformers` opcional; almacenamiento local (SQLite/FAISS ligero).
- Criterios de aceptación: inserción/consulta deterministas; latencia < 200 ms; coherencia del resultado.
- Pruebas: unitarias y e2e con `LucyAI` y datos sintéticos.

**Día 12: Interface Web Básica**
- Objetivo: exponer Lucy por API y canal web simple.
- Integración: `src/lucy/web/app.py` (FastAPI) orquesta `LucyAI`, `ConversationDB`, `ConfigManager` y `LoggingSystem`.
- Estrategia: endpoints REST `/chat`, `/context`; WebSocket para tiempo real; CORS controlado.
- Acciones: construir app, dependencias, routers y middleware; cliente simple opcional.
- Configuración: `web.enabled`, `web.host`, `web.port`, `web.cors`.
- Requisitos: `fastapi>=0.115`, `uvicorn[standard]>=0.30`, `pydantic>=2.6`, `websockets`.
- Criterios de aceptación: endpoints funcionales, integración correcta y latencia estable.
- Pruebas: integración con test client y simulaciones de flujo.

**Día 13: Comandos de Sistema**
- Objetivo: ejecutar acciones locales seguras y trazables.
- Integración: `src/lucy/system/runner.py` con whitelist, auditoría y configuración dinámica.
- Estrategia: validar comandos, sandbox cuando aplique, logs ricos.
- Acciones: implementar runner, lista permitida y prompts claros; manejo de errores.
- Configuración: `system_commands.enabled`, `system_commands.allowed_commands`.
- Criterios de aceptación: sin escalación de privilegios; auditoría completa.
- Pruebas: unitarias con sandbox y simulación de condiciones de error.

**Día 14: Notificaciones**
- Objetivo: recordatorios y avisos programables con persistencia ligera.
- Integración: `src/lucy/notifications/scheduler.py` conectado a `ConversationDB` y `LoggingSystem`.
- Estrategia: scheduler simple, colas ligeras y conectores (calendario/email opcional).
- Acciones: programar, cancelar y disparar notificaciones; persistencia básica.
- Configuración: `notifications.enabled`, `notifications.channels`, `notifications.schedule`.
- Criterios de aceptación: programación y disparo deterministas; logs visibles.
- Pruebas: unitarias de programación, cancelación y entrega simulada.

---

### Fase 3: Inteligencia Avanzada (Días 15-21)
- Enfoque incremental con validaciones fuertes; cada subcomponente integra logging y pruebas.
- Prioridades: datos (Día 15), generación (Día 16), voz (Día 17), visión (Día 18), cloud (Día 19), recomendaciones (Día 20), automatización (Día 21).

**Día 15: Análisis de Datos y Reportes**
- Objetivo: generar insights a partir de conversaciones y métricas.
- Integración: `src/lucy/analytics` consume `ConversationDB` y logs; exporta CSV/JSON.
- Acciones: agregados por intención/idioma, filtros por rango; reporte de latencias.
- Configuración: `analytics.enabled`, `analytics.outputs`.
- Criterios: export determinista y consistencia de agregados.
- Pruebas: unitarias sobre agregados y formatos; integración con datos de prueba.

**Día 16: Generación de Contenido**
- Objetivo: producir texto funcional con plantillas y ML opcional.
- Integración: `src/lucy/generation` llamado por `LucyAI` bajo intención específica.
- Acciones: plantillas parametrizadas, control de longitud y coherencia.
- Configuración: `generation.enabled`, `generation.templates`.
- Criterios: coherencia mínima; golden tests para estabilidad.
- Pruebas: unitarias y validación de calidad.

**Día 17: Reconocimiento de Voz**
- Objetivo: transcribir audio a texto localmente.
- Integración: `src/lucy/voice` y conexión con web; usa `ConfigManager`.
- Acciones: captura, transcripción y manejo de errores.
- Requisitos: `SpeechRecognition`/`Vosk`.
- Criterios: precisión mínima y estabilidad; latencia aceptable.
- Pruebas: unitarias con muestras pregrabadas.

**Día 18: Visión por Computadora**
- Objetivo: tareas básicas de imagen (detección simple, OCR opcional).
- Integración: `src/lucy/vision` con utilidades; resultados consumidos por `LucyAI`.
- Requisitos: `opencv-python` o `pillow`.
- Criterios: funcionalidad mínima estable.
- Pruebas: unitarias sobre imágenes de ejemplo.

**Día 19: Servicios Cloud**
- Objetivo: integrar servicios externos cloud de forma segura (opcional).
- Integración: `src/lucy/cloud` con adaptadores; credenciales seguras.
- Acciones: operaciones básicas (almacenamiento/servicios ML).
- Criterios: seguridad y configuración externa; sin datos sensibles en logs.
- Pruebas: mocks y validación de rutas críticas.

**Día 20: Recomendaciones**
- Objetivo: sugerencias basadas en historial y preferencias.
- Integración: `src/lucy/recommender` usando `ConversationDB` y/o `memory`.
- Acciones: heurísticas y ML ligero; métricas offline.
- Criterios: relevancia y estabilidad.
- Pruebas: unitarias y evaluación offline.

**Día 21: Automatización Avanzada (Workflows)**
- Objetivo: orquestar tareas multi-paso con idempotencia.
- Integración: `src/lucy/workflows` invocado por `LucyAI` según intención.
- Acciones: DSL simple y ejecución controlada; trazabilidad completa.
- Criterios: idempotencia y logs; recuperación de fallos.
- Pruebas: unitarias y e2e de flujos.

---

### Fase 4: Integración y Distribución (Días 22-30)
- Cerrar APIs, GUI desktop, web completa, seguridad y QA; culminar en release y plan de mantenimiento.

---

### Mapa de Trazabilidad (Objetivos → Acciones → Pruebas → Métricas)
- Objetivo: "Respuestas rápidas" → Acciones: mejoras en LucyAI, cache → Pruebas: latencia y carga → Métricas: p95 < 2s.
- Objetivo: "Confiabilidad" → Acciones: cobertura de pruebas → Pruebas: unitarias/integración → Métricas: cobertura ≥ 90% (meta).
- Objetivo: "Aprendizaje" → Acciones: training reproducible → Pruebas: evaluación de modelo → Métricas: F1 ≥ 0.85.

### Calidad, Testing y CI
- Pruebas: `pytest -q`; integración para `LucyAI`, `Database`, `ConfigManager`, `Training`.
- Cobertura: umbral mínimo 85% (subida progresiva a 90%).
- CI local: scripts en `run_lucy.*` y verificación previa a release.

### Seguridad y Privacidad
- Logs sin datos sensibles; cifrado en repositorios persistentes.
- Autenticación para APIs; auditoría de accesos.

### Riesgos y Mitigación
- Datos inconsistentes → validadores y pruebas de datos.
- Rendimiento insuficiente → profiling y cache.
- Dependencias externas → mock y aislamiento.

### Tecnologías por Implementar (mapeo)
- Backend: FastAPI (Fase 2 Día 12), SQLAlchemy (DB avanzada), Redis (cache), Celery (tareas async).
- Frontend: React/Vue (Fase 4 Día 24), WebSocket (Día 12), PWA.
- IA/ML: Transformers, spaCy, scikit-learn; OpenCV (Fase 3 Día 18).
- Infra: Docker, GitHub Actions, AWS/GCP, Prometheus.

### Métricas de Éxito
- Tiempo de respuesta < 2 segundos (p95 en escenarios comunes).
- Precisión de respuestas > 85% (PLN base; objetivo 90% en avance).
- Cobertura de pruebas > 90% (meta; umbral operativo 85%).
- Documentación completa al 100% (actualizada por cambios de código).
- 0 vulnerabilidades críticas (escaneo regular).
- Soporte para 10+ idiomas (detección y respuestas consistentes).

### Diagrama de Flujo Operativo (resumen)
```
Usuario → LucyAI → Detección de intención → Generación de respuesta
          │              │                          │
          │              └── usa modelos y reglas   └── texto final
          ├─► ConversationDB (historial y contexto)
          ├─► LoggingSystem (métricas y auditoría)
          └─► ConfigManager (ajustes en runtime)
```

### Notas de Interconexión
- Cada funcionalidad nueva debe registrar métricas y respetar configuración dinámica.
- Cambios en modelos implican actualización de `LucyAI` y validación en `tests/`.
- DB y Config son dependencias transversales; cualquier cambio requiere verificación de compatibilidad.